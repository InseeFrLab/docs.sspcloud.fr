[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bienvenue sur le SSP Cloud !",
    "section": "",
    "text": "Instance ouverte du projet Onyxia, le SSP Cloud est une plateforme mutualisée de traitement de données, ou “Datalab”. Elle est dédiée à l’expérimentation autour des méthodes de datascience à partir de données ouvertes. A travers ce tutoriel, nous vous proposons une visite guidée du Datalab pour être rapidement opérationnel dans l’utilisation de ses services.\n\n\n\n\n\n\nWarning\n\n\n\nLes conditions d’utilisation du SSP Cloud sont consultables à cette adresse. Nous rappelons que le SSP Cloud est destiné exclusivement au traitement de données publiques et non-sensibles. Des projets d’expérimentation mobilisant des données non ouvertes peuvent être menés en concertation avec l’équipe du projet Onyxia, sous réserve de se conformer aux règles de sécurité spécifiques au projet.\n\n\n\n\nLe catalogue de services est au centre de l’utilisation du SSP Cloud. Il propose un ensemble de services destinés aux traitements statistiques de données ainsi qu’à la gestion complète des projets de data science.\n\n\n\nPour lancer un service, il suffit de cliquer sur le bouton Lancer du service désiré\nUne page centrée sur le service demandé s’ouvre alors, qui offre plusieurs possibilités :\n\ncliquer à nouveau sur le bouton Lancer pour lancer le service avec sa configuration par défaut ;\npersonnaliser le nom que portera l’instance une fois le service lancé ;\ndérouler un menu de configuration afin de personnaliser la configuration du service avant de le lancer ;\nsauvegarder une configuration personnalisée en cliquant sur le signet en haut à droite du service.\n\n\nLa configuration précise des services du SSP Cloud constitue un usage avancé et n’est donc pas traité dans ce tutoriel, mais dans d’autres pages de ce site documentaire.\n\n\n\n\nL’action de lancer un service amène automatiquement sur la page Mes Services, où sont listées toutes les instances en activité sur le compte de l’utilisateur.\n\nUne fois le service lancé, un bouton Ouvrir apparaît qui permet l’accès au service. Un mot de passe — et, selon les services, un nom d’utilisateur — est généralement requis pour pouvoir utiliser le service. Ces informations sont disponibles dans le README associé au service, auquel on accède en cliquant sur le bouton du même nom.\n\n\n\nSupprimer une instance d’un service s’effectue simplement en cliquant sur l’icône en forme de poubelle en dessous de l’instance.\n\n\n\n\n\n\nCaution\n\n\n\nPour certains services, la suppression d’une instance entraîne la suppression de toutes les données associées, et cette action est irrémédiable. Il est donc nécessaire de toujours bien lire le README associé à l’instance, qui précise les conséquences d’une suppression de l’instance. De manière générale, il est très important de s’assurer que les données ainsi que le code utilisés sont sauvegardés avant de supprimer l’instance. L’idéal est de versionner son code avec Git et de procéder à des sauvegardes régulières des données à l’aide du système de stockage S3.\n\n\n\n\n\n\n\n\nCaution\n\n\n\nLes ressources mises à disposition pour l’execution des services sont partagées entre les différents utilisateurs du SSP Cloud. Veuillez à ne pas laisser en cours des services dont vous ne faites plus l’usage. Nous procédons parfois à une suppression systématique des instances inactives depuis un certain temps, afin de libérer des ressources.\n\n\n\n\n\n\nLe support et l’aide à l’utilisation du SSP Cloud sont effectuées sur deux outils de communication :\n\nSur le Slack Onyxia dans le canal dédié #sspcloud. Toute question sur l’utilisation du SSP Cloud ou suggestion d’amélioration y sont les bienvenues.\nSur un salon dédié du service de messagerie instantanée interministériel de l’état Francais Tchap pour les agents publiques français."
  },
  {
    "objectID": "index.html#le-catalogue-de-services",
    "href": "index.html#le-catalogue-de-services",
    "title": "Bienvenue sur le SSP Cloud !",
    "section": "",
    "text": "Le catalogue de services est au centre de l’utilisation du SSP Cloud. Il propose un ensemble de services destinés aux traitements statistiques de données ainsi qu’à la gestion complète des projets de data science.\n\n\n\nPour lancer un service, il suffit de cliquer sur le bouton Lancer du service désiré\nUne page centrée sur le service demandé s’ouvre alors, qui offre plusieurs possibilités :\n\ncliquer à nouveau sur le bouton Lancer pour lancer le service avec sa configuration par défaut ;\npersonnaliser le nom que portera l’instance une fois le service lancé ;\ndérouler un menu de configuration afin de personnaliser la configuration du service avant de le lancer ;\nsauvegarder une configuration personnalisée en cliquant sur le signet en haut à droite du service.\n\n\nLa configuration précise des services du SSP Cloud constitue un usage avancé et n’est donc pas traité dans ce tutoriel, mais dans d’autres pages de ce site documentaire.\n\n\n\n\nL’action de lancer un service amène automatiquement sur la page Mes Services, où sont listées toutes les instances en activité sur le compte de l’utilisateur.\n\nUne fois le service lancé, un bouton Ouvrir apparaît qui permet l’accès au service. Un mot de passe — et, selon les services, un nom d’utilisateur — est généralement requis pour pouvoir utiliser le service. Ces informations sont disponibles dans le README associé au service, auquel on accède en cliquant sur le bouton du même nom.\n\n\n\nSupprimer une instance d’un service s’effectue simplement en cliquant sur l’icône en forme de poubelle en dessous de l’instance.\n\n\n\n\n\n\nCaution\n\n\n\nPour certains services, la suppression d’une instance entraîne la suppression de toutes les données associées, et cette action est irrémédiable. Il est donc nécessaire de toujours bien lire le README associé à l’instance, qui précise les conséquences d’une suppression de l’instance. De manière générale, il est très important de s’assurer que les données ainsi que le code utilisés sont sauvegardés avant de supprimer l’instance. L’idéal est de versionner son code avec Git et de procéder à des sauvegardes régulières des données à l’aide du système de stockage S3.\n\n\n\n\n\n\n\n\nCaution\n\n\n\nLes ressources mises à disposition pour l’execution des services sont partagées entre les différents utilisateurs du SSP Cloud. Veuillez à ne pas laisser en cours des services dont vous ne faites plus l’usage. Nous procédons parfois à une suppression systématique des instances inactives depuis un certain temps, afin de libérer des ressources."
  },
  {
    "objectID": "index.html#support",
    "href": "index.html#support",
    "title": "Bienvenue sur le SSP Cloud !",
    "section": "",
    "text": "Le support et l’aide à l’utilisation du SSP Cloud sont effectuées sur deux outils de communication :\n\nSur le Slack Onyxia dans le canal dédié #sspcloud. Toute question sur l’utilisation du SSP Cloud ou suggestion d’amélioration y sont les bienvenues.\nSur un salon dédié du service de messagerie instantanée interministériel de l’état Francais Tchap pour les agents publiques français."
  },
  {
    "objectID": "content/tutorials/set-up-environment.html",
    "href": "content/tutorials/set-up-environment.html",
    "title": "🚧 Travail en cours 🚧",
    "section": "",
    "text": "🚧 Travail en cours 🚧\nVous pouvez toutefois vous référez à la version anglaise"
  },
  {
    "objectID": "content/tutorials/course-structure.html",
    "href": "content/tutorials/course-structure.html",
    "title": "🚧 Travail en cours 🚧",
    "section": "",
    "text": "🚧 Travail en cours 🚧\nVous pouvez toutefois vous référez à la version anglaise"
  },
  {
    "objectID": "content/storage.html",
    "href": "content/storage.html",
    "title": "Stockage de données",
    "section": "",
    "text": "La solution de stockage de fichiers associée au Datalab est MinIO, un système de stockage d’objets basé sur le cloud, compatible avec l’API S3 d’Amazon. Concrètement, cela a plusieurs avantages :\n\nles fichiers stockés sont accessibles facilement et à n’importe quel endroit : un fichier est accessible directement via une simple URL, qui peut être partagée ;\nil est possible d’accéder aux fichiers stockés directement dans les services de data science (R, Python…) proposés sur le Datalab, sans avoir besoin de copier les fichiers localement au préalable, ce qui améliore fortement la reproductibilité des analyses.\n\n\n\n\nMinIO Schema\n\n\n\n\n\n\n\nLa page Mes fichiers du Datalab prend la forme d’un explorateur de fichiers présentant les différents buckets (dépôts) auxquels l’utilisateur a accès.\nChaque utilisateur dispose par défaut d’un bucket personnel pour stocker ses fichiers. Au sein de ce bucket, deux options sont possibles :\n\n“créer un répertoire” : crée un répertoire dans le bucket/répertoire courant, de manière hiérarchique, comme dans un système de fichiers traditionnel ;\n“uploader** un fichier**” : upload un ou plusieurs fichiers dans le répertoire courant.\n\n\n\n\n\n\n\nNote\n\n\n\nL’interface graphique du stockage de données sur le Datalab est encore en cours de construction. Elle peut à ce titre présenter des problèmes de réactivité. Pour des opérations fréquentes sur le stockage de fichiers, il peut être préférable d’interagir avec MinIO via le terminal.\n\n\n\n\n\nLa politique de contrôle d’accès au stockage S3 interdit par défaut l’accès aux buckets des autres utilisateurs du SSPCloud, à l’exception du dossier diffusion directement à la racine de chaque bucket qui est accessible en lecture seule à l’ensemble des utilisateurs.\nPour partager des données, il vous suffit ainsi de créer un dossier diffusion directement à la racine de votre bucket personnel et d’y déposer les éléments que vous souhaitez rendre accessibles aux autres utilisateurs de la plateforme.\nIl est également possible de configurer manuellement la politique de partage afin d’ajuster plus finement les permissions. Pour ce faire il est actuellement nécessaire d’interagir avec MinIO via un terminal qui vous permet d’accéder à des fonctionnalités avancées.\nEn utilisant MinIO Client, vous pouvez rendre un dossier publiquement accessible avec la commande suivante :\nmc anonymous set download s3/&lt;votre nom d'utilisateur&gt;/&lt;le dossier que vous voulez rendre publique&gt;\nCette commande permet d’accorder des droits de téléchargement publics pour le dossier spécifié.\nPour des besoins plus spécifiques de contrôle d’accès, comme la gestion de droits d’accès anonymes ou restreints, consultez la documentation officielle de MinIO Client.\nUn tutoriel interactif expliquant comment utiliser VSCode au sein du datalab pour partager un dossier S3 est disponible ici\n\n\n\n\n\n\nNote\n\n\n\nDans le cadre de projets collaboratifs, il peut être intéressant pour les différents participants d’avoir accès à un espace de stockage commun. Il est possible pour cet usage de créer des buckets partagés sur MinIO. N’hésitez pas à nous contacter via les canaux précisés sur la page “Première utilisation” si vous souhaitez porter des projets open-data sur le Datalab.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nConformément aux conditions d’utilisation, seules des données de type open data ou ne présentant aucune sensibilité peuvent être stockées sur le Datalab. Le fait qu’un fichier ait un statut de diffusion “privé” ne suffit pas à garantir sa confidentialité.\n\n\n\n\n\n\nLes identifiants d’accès nécessaires pour accéder à des données sur MinIO sont pré-configurés dans les différents services du Datalab, accessibles sous la forme de variables d’environnement. Ainsi, l’import et l’export de fichiers à partir des services est grandement facilité.\n\n\n\nRPythonmc (terminal)\n\n\nEn R, l’interaction avec un système de fichiers compatible S3 est rendu possible par la librairie aws.s3.\nlibrary(aws.s3)\n\n\nEn Python, l’interaction avec un système de fichiers compatible S3 est rendu possible par deux librairies :\n\nBoto3, une librairie créée et maintenue par Amazon ;\nS3Fs, une librairie qui permet d’interagir avec les fichiers stockés à l’instar d’un filesystem classique.\n\nPour cette raison et parce que S3Fs est utilisée par défaut par la librairie pandas pour gérer les connections S3, nous allons présenter la gestion du stockage sur MinIO via Python à travers cette librairie.\nimport os\nimport s3fs\n\n# Create filesystem object\nS3_ENDPOINT_URL = \"https://\" + os.environ[\"AWS_S3_ENDPOINT\"]\nfs = s3fs.S3FileSystem(client_kwargs={'endpoint_url': S3_ENDPOINT_URL})\n\n\nMinIO propose un client en ligne de commande (mc) qui permet d’interagir avec le système de stockage à la manière d’un filesystem UNIX classique. Ce client est installé par défaut et accessible via un terminal dans les différents services du Datalab.\nLe client MinIO propose les commandes UNIX de base, telles que ls, cat, cp, etc. La liste complète est disponible dans la documentation du client.\n\n\n\n\n\n\n\nRPythonmc (terminal)\n\n\naws.s3::get_bucket(\"donnees-insee\", region = \"\")\n\n\nfs.ls(\"donnees-insee\")\n\n\nLe stockage du Datalab est accessible via l’alias s3. Par exemple, pour lister les fichiers du bucket donnees-insee :\nmc ls s3/donnees-insee\n\n\n\n\n\n\n\nRPythonmc (terminal)\n\n\nBUCKET &lt;- \"donnees-insee\"\nFILE_KEY_S3 &lt;- \"diffusion/BPE/2019/BPE_ENS.csv\"\n\ndf &lt;-\n  aws.s3::s3read_using(\n    FUN = readr::read_delim,\n    # Mettre les options de FUN ici\n    delim = \";\",\n    object = FILE_KEY_S3,\n    bucket = BUCKET,\n    opts = list(\"region\" = \"\")\n  )\n\n\nLe package S3Fs permet d’interagir avec les fichiers stockés sur MinIO comme s’il s’agissait de fichiers locaux. La syntaxe est donc très familière pour les utilisateurs de Python. Par exemple, pour importer/exporter des données tabulaires via pandas :\nimport pandas as pd\n\nBUCKET = \"donnees-insee\"\nFILE_KEY_S3 = \"diffusion/BPE/2019/BPE_ENS.csv\"\nFILE_PATH_S3 = BUCKET + \"/\" + FILE_KEY_S3\n\nwith fs.open(FILE_PATH_S3, mode=\"rb\") as file_in:\n    df_bpe = pd.read_csv(file_in, sep=\";\")\n\n\nPour copier les données d’un bucket sur MinIO vers le service local :\nmc cp s3/donnees-insee/diffusion/BPE/2019/BPE_ENS.csv ./BPE_ENS.csv\n\n\n\n\n\n\nWarning\n\n\n\nCopier les fichiers dans le service local n’est généralement pas une bonne pratique : cela limite la reproductibilité des analyses, et devient rapidement impossible avec des volumes importants de données. Il est donc préférable de prendre l’habitude d’importer les données comme des fichiers directement dans R/Python.\n\n\n\n\n\n\n\n\n\nRPythonmc (terminal)\n\n\nBUCKET_OUT = \"&lt;mon_bucket&gt;\"\nFILE_KEY_OUT_S3 = \"mon_dossier/BPE_ENS.csv\"\n\naws.s3::s3write_using(\n    df,\n    FUN = readr::write_csv,\n    object = FILE_KEY_OUT_S3,\n    bucket = BUCKET_OUT,\n    opts = list(\"region\" = \"\")\n)\n\n\nBUCKET_OUT = \"&lt;mon_bucket&gt;\"\nFILE_KEY_OUT_S3 = \"mon_dossier/BPE_ENS.csv\"\nFILE_PATH_OUT_S3 = BUCKET_OUT + \"/\" + FILE_KEY_OUT_S3\n\nwith fs.open(FILE_PATH_OUT_S3, 'w') as file_out:\n    df_bpe.to_csv(file_out)\n\n\nPour copier les données du service local vers un bucket sur MinIO:\nmc cp chemin/local/vers/mon/fichier.csv s3/&lt;mon_bucket&gt;/chemin/distant/vers/mon/fichier.csv\n\n\n\n\n\n\n\nL’accès au stockage MinIO est possible via un token (jeton d’accès) personnel, valide 7 jours, et automatiquement régénéré à échéances régulières sur le SSP Cloud. Lorsqu’un token a expiré, les services créés avant la date d’expiration (avec le précédent token) ne peuvent plus accéder au stockage ; le service concerné apparaît alors marqué en rouge dans la page Mes Services. Dans ce cas, deux possibilités :\n\nouvrir un nouveau service sur le Datalab, qui aura par défaut un nouveau token à jour ;\nremplacer manuellement les jetons périmés par des nouveaux. Des scripts indiquant la manière de faire pour les différentes utilisations de MinIO (R/Python/mc) sont disponibles ici. Il suffit de choisir le script pertinent et de l’exécuter dans son environnement de travail courant.\n\n\n\n\n\n\nPour des raisons de sécurité, l’authentification à MinIO utilisée par défault dans les services interactifs du SSP Cloud repose un sur jeton d’accès temporaire. Dans le cadre de projets impliquant des traitements périodiques ou le déploiement d’applications, on peut avoir besoin d’un accès plus pérenne à des données sur MinIO.\nDans ce cas, on utilise un compte de service, c’est à dire un compte qui est rattaché à un certain projet ou une certaine application plutôt qu’à une personne. En termes techniques, au lieu de s’authentifier à MinIO via un triplet (access key id, secret access key et session token), on va utiliser un couple (access key id, secret access key) qui donne des permissions en lecture/écriture à un certain bucket de projet.\nLa procédure de création d’un compte de service est décrite ci-dessous.\n\nInterface graphiqueTerminal (mc)\n\n\n\nOuvrir la console MinIO\nOuvrir l’onglet Access Keys\nLes informations du compte de service sont pré-générées. Il est possible de modifier l’access-key pour lui donner un nom plus simple.\nLa policy précisant les droits est également pré-générée. Idéalement, on restreint la policy pour qu’elle ne concerne que le/les bucket(s) du projet.\nUne fois le compte de service généré, l’access-key et la secret-access-key peuvent être utilisées pour authentifier les services / applications au bucket spécifié\n\n\n\n\nCréer un service sur le SSP Cloud avec des accès MinIO à jour. Confirmer que la connection fonctionne avec :\n\nmc ls s3/&lt;nom_utilisateur&gt;\n\nGénérer un fichier policy.json avec le contenu suivant, en remplaçant (deux fois) projet-&lt;mon_projet&gt; par le nom du bucket concerné :\n\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n     {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n       \"s3:*\"\n      ],\n      \"Resource\": [\n       \"arn:aws:s3:::projet-&lt;mon_projet&gt;\",\n       \"arn:aws:s3:::projet-&lt;mon_projet&gt;/*\"\n      ]\n     }\n    ]\n  }\n\nDans un terminal, générer le compte de service avec la commande suivante :\n\nmc admin accesskey create s3 $AWS_ACCESS_KEY_ID --access-key=\"&lt;access-key&gt;\" --secret-key=\"&lt;secret-access-key&gt;\" --policy=\"policy.json\"\nen remplaçant &lt;access-key&gt; et &lt;secret-access-key&gt; par des noms de votre choix. Idéalement, on donnera un nom simple comme access-key (ex : sa-projet-nomduprojet) mais une clé complexe comme secret-access-key, générable par exemple avec le client gpg :\ngpg --gen-random --armor 1 16\n\nVous pouvez désormais utiliser l’access-key et la secret-access-key pour authentifier les services / applications au bucket spécifié.\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nAttention, les informations d’authentification générées n’apparaissent qu’une seule fois. Elles peuvent ensuite être stockées dans un gestionnaire de mot de passe, un service de stockage de secrets comme Vault, ou bien via la feature d’options de projet d’Onyxia qui permet d’importer le compte de service directement dans les services au moment de leur configuration."
  },
  {
    "objectID": "content/storage.html#principes",
    "href": "content/storage.html#principes",
    "title": "Stockage de données",
    "section": "",
    "text": "La solution de stockage de fichiers associée au Datalab est MinIO, un système de stockage d’objets basé sur le cloud, compatible avec l’API S3 d’Amazon. Concrètement, cela a plusieurs avantages :\n\nles fichiers stockés sont accessibles facilement et à n’importe quel endroit : un fichier est accessible directement via une simple URL, qui peut être partagée ;\nil est possible d’accéder aux fichiers stockés directement dans les services de data science (R, Python…) proposés sur le Datalab, sans avoir besoin de copier les fichiers localement au préalable, ce qui améliore fortement la reproductibilité des analyses.\n\n\n\n\nMinIO Schema"
  },
  {
    "objectID": "content/storage.html#gérer-ses-données",
    "href": "content/storage.html#gérer-ses-données",
    "title": "Stockage de données",
    "section": "",
    "text": "La page Mes fichiers du Datalab prend la forme d’un explorateur de fichiers présentant les différents buckets (dépôts) auxquels l’utilisateur a accès.\nChaque utilisateur dispose par défaut d’un bucket personnel pour stocker ses fichiers. Au sein de ce bucket, deux options sont possibles :\n\n“créer un répertoire” : crée un répertoire dans le bucket/répertoire courant, de manière hiérarchique, comme dans un système de fichiers traditionnel ;\n“uploader** un fichier**” : upload un ou plusieurs fichiers dans le répertoire courant.\n\n\n\n\n\n\n\nNote\n\n\n\nL’interface graphique du stockage de données sur le Datalab est encore en cours de construction. Elle peut à ce titre présenter des problèmes de réactivité. Pour des opérations fréquentes sur le stockage de fichiers, il peut être préférable d’interagir avec MinIO via le terminal.\n\n\n\n\n\nLa politique de contrôle d’accès au stockage S3 interdit par défaut l’accès aux buckets des autres utilisateurs du SSPCloud, à l’exception du dossier diffusion directement à la racine de chaque bucket qui est accessible en lecture seule à l’ensemble des utilisateurs.\nPour partager des données, il vous suffit ainsi de créer un dossier diffusion directement à la racine de votre bucket personnel et d’y déposer les éléments que vous souhaitez rendre accessibles aux autres utilisateurs de la plateforme.\nIl est également possible de configurer manuellement la politique de partage afin d’ajuster plus finement les permissions. Pour ce faire il est actuellement nécessaire d’interagir avec MinIO via un terminal qui vous permet d’accéder à des fonctionnalités avancées.\nEn utilisant MinIO Client, vous pouvez rendre un dossier publiquement accessible avec la commande suivante :\nmc anonymous set download s3/&lt;votre nom d'utilisateur&gt;/&lt;le dossier que vous voulez rendre publique&gt;\nCette commande permet d’accorder des droits de téléchargement publics pour le dossier spécifié.\nPour des besoins plus spécifiques de contrôle d’accès, comme la gestion de droits d’accès anonymes ou restreints, consultez la documentation officielle de MinIO Client.\nUn tutoriel interactif expliquant comment utiliser VSCode au sein du datalab pour partager un dossier S3 est disponible ici\n\n\n\n\n\n\nNote\n\n\n\nDans le cadre de projets collaboratifs, il peut être intéressant pour les différents participants d’avoir accès à un espace de stockage commun. Il est possible pour cet usage de créer des buckets partagés sur MinIO. N’hésitez pas à nous contacter via les canaux précisés sur la page “Première utilisation” si vous souhaitez porter des projets open-data sur le Datalab.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nConformément aux conditions d’utilisation, seules des données de type open data ou ne présentant aucune sensibilité peuvent être stockées sur le Datalab. Le fait qu’un fichier ait un statut de diffusion “privé” ne suffit pas à garantir sa confidentialité."
  },
  {
    "objectID": "content/storage.html#utiliser-des-données-stockées-sur-minio",
    "href": "content/storage.html#utiliser-des-données-stockées-sur-minio",
    "title": "Stockage de données",
    "section": "",
    "text": "Les identifiants d’accès nécessaires pour accéder à des données sur MinIO sont pré-configurés dans les différents services du Datalab, accessibles sous la forme de variables d’environnement. Ainsi, l’import et l’export de fichiers à partir des services est grandement facilité.\n\n\n\nRPythonmc (terminal)\n\n\nEn R, l’interaction avec un système de fichiers compatible S3 est rendu possible par la librairie aws.s3.\nlibrary(aws.s3)\n\n\nEn Python, l’interaction avec un système de fichiers compatible S3 est rendu possible par deux librairies :\n\nBoto3, une librairie créée et maintenue par Amazon ;\nS3Fs, une librairie qui permet d’interagir avec les fichiers stockés à l’instar d’un filesystem classique.\n\nPour cette raison et parce que S3Fs est utilisée par défaut par la librairie pandas pour gérer les connections S3, nous allons présenter la gestion du stockage sur MinIO via Python à travers cette librairie.\nimport os\nimport s3fs\n\n# Create filesystem object\nS3_ENDPOINT_URL = \"https://\" + os.environ[\"AWS_S3_ENDPOINT\"]\nfs = s3fs.S3FileSystem(client_kwargs={'endpoint_url': S3_ENDPOINT_URL})\n\n\nMinIO propose un client en ligne de commande (mc) qui permet d’interagir avec le système de stockage à la manière d’un filesystem UNIX classique. Ce client est installé par défaut et accessible via un terminal dans les différents services du Datalab.\nLe client MinIO propose les commandes UNIX de base, telles que ls, cat, cp, etc. La liste complète est disponible dans la documentation du client.\n\n\n\n\n\n\n\nRPythonmc (terminal)\n\n\naws.s3::get_bucket(\"donnees-insee\", region = \"\")\n\n\nfs.ls(\"donnees-insee\")\n\n\nLe stockage du Datalab est accessible via l’alias s3. Par exemple, pour lister les fichiers du bucket donnees-insee :\nmc ls s3/donnees-insee\n\n\n\n\n\n\n\nRPythonmc (terminal)\n\n\nBUCKET &lt;- \"donnees-insee\"\nFILE_KEY_S3 &lt;- \"diffusion/BPE/2019/BPE_ENS.csv\"\n\ndf &lt;-\n  aws.s3::s3read_using(\n    FUN = readr::read_delim,\n    # Mettre les options de FUN ici\n    delim = \";\",\n    object = FILE_KEY_S3,\n    bucket = BUCKET,\n    opts = list(\"region\" = \"\")\n  )\n\n\nLe package S3Fs permet d’interagir avec les fichiers stockés sur MinIO comme s’il s’agissait de fichiers locaux. La syntaxe est donc très familière pour les utilisateurs de Python. Par exemple, pour importer/exporter des données tabulaires via pandas :\nimport pandas as pd\n\nBUCKET = \"donnees-insee\"\nFILE_KEY_S3 = \"diffusion/BPE/2019/BPE_ENS.csv\"\nFILE_PATH_S3 = BUCKET + \"/\" + FILE_KEY_S3\n\nwith fs.open(FILE_PATH_S3, mode=\"rb\") as file_in:\n    df_bpe = pd.read_csv(file_in, sep=\";\")\n\n\nPour copier les données d’un bucket sur MinIO vers le service local :\nmc cp s3/donnees-insee/diffusion/BPE/2019/BPE_ENS.csv ./BPE_ENS.csv\n\n\n\n\n\n\nWarning\n\n\n\nCopier les fichiers dans le service local n’est généralement pas une bonne pratique : cela limite la reproductibilité des analyses, et devient rapidement impossible avec des volumes importants de données. Il est donc préférable de prendre l’habitude d’importer les données comme des fichiers directement dans R/Python.\n\n\n\n\n\n\n\n\n\nRPythonmc (terminal)\n\n\nBUCKET_OUT = \"&lt;mon_bucket&gt;\"\nFILE_KEY_OUT_S3 = \"mon_dossier/BPE_ENS.csv\"\n\naws.s3::s3write_using(\n    df,\n    FUN = readr::write_csv,\n    object = FILE_KEY_OUT_S3,\n    bucket = BUCKET_OUT,\n    opts = list(\"region\" = \"\")\n)\n\n\nBUCKET_OUT = \"&lt;mon_bucket&gt;\"\nFILE_KEY_OUT_S3 = \"mon_dossier/BPE_ENS.csv\"\nFILE_PATH_OUT_S3 = BUCKET_OUT + \"/\" + FILE_KEY_OUT_S3\n\nwith fs.open(FILE_PATH_OUT_S3, 'w') as file_out:\n    df_bpe.to_csv(file_out)\n\n\nPour copier les données du service local vers un bucket sur MinIO:\nmc cp chemin/local/vers/mon/fichier.csv s3/&lt;mon_bucket&gt;/chemin/distant/vers/mon/fichier.csv"
  },
  {
    "objectID": "content/storage.html#renouveler-des-jetons-daccès-tokens-périmés",
    "href": "content/storage.html#renouveler-des-jetons-daccès-tokens-périmés",
    "title": "Stockage de données",
    "section": "",
    "text": "L’accès au stockage MinIO est possible via un token (jeton d’accès) personnel, valide 7 jours, et automatiquement régénéré à échéances régulières sur le SSP Cloud. Lorsqu’un token a expiré, les services créés avant la date d’expiration (avec le précédent token) ne peuvent plus accéder au stockage ; le service concerné apparaît alors marqué en rouge dans la page Mes Services. Dans ce cas, deux possibilités :\n\nouvrir un nouveau service sur le Datalab, qui aura par défaut un nouveau token à jour ;\nremplacer manuellement les jetons périmés par des nouveaux. Des scripts indiquant la manière de faire pour les différentes utilisations de MinIO (R/Python/mc) sont disponibles ici. Il suffit de choisir le script pertinent et de l’exécuter dans son environnement de travail courant."
  },
  {
    "objectID": "content/storage.html#usages-avancés",
    "href": "content/storage.html#usages-avancés",
    "title": "Stockage de données",
    "section": "",
    "text": "Pour des raisons de sécurité, l’authentification à MinIO utilisée par défault dans les services interactifs du SSP Cloud repose un sur jeton d’accès temporaire. Dans le cadre de projets impliquant des traitements périodiques ou le déploiement d’applications, on peut avoir besoin d’un accès plus pérenne à des données sur MinIO.\nDans ce cas, on utilise un compte de service, c’est à dire un compte qui est rattaché à un certain projet ou une certaine application plutôt qu’à une personne. En termes techniques, au lieu de s’authentifier à MinIO via un triplet (access key id, secret access key et session token), on va utiliser un couple (access key id, secret access key) qui donne des permissions en lecture/écriture à un certain bucket de projet.\nLa procédure de création d’un compte de service est décrite ci-dessous.\n\nInterface graphiqueTerminal (mc)\n\n\n\nOuvrir la console MinIO\nOuvrir l’onglet Access Keys\nLes informations du compte de service sont pré-générées. Il est possible de modifier l’access-key pour lui donner un nom plus simple.\nLa policy précisant les droits est également pré-générée. Idéalement, on restreint la policy pour qu’elle ne concerne que le/les bucket(s) du projet.\nUne fois le compte de service généré, l’access-key et la secret-access-key peuvent être utilisées pour authentifier les services / applications au bucket spécifié\n\n\n\n\nCréer un service sur le SSP Cloud avec des accès MinIO à jour. Confirmer que la connection fonctionne avec :\n\nmc ls s3/&lt;nom_utilisateur&gt;\n\nGénérer un fichier policy.json avec le contenu suivant, en remplaçant (deux fois) projet-&lt;mon_projet&gt; par le nom du bucket concerné :\n\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n     {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n       \"s3:*\"\n      ],\n      \"Resource\": [\n       \"arn:aws:s3:::projet-&lt;mon_projet&gt;\",\n       \"arn:aws:s3:::projet-&lt;mon_projet&gt;/*\"\n      ]\n     }\n    ]\n  }\n\nDans un terminal, générer le compte de service avec la commande suivante :\n\nmc admin accesskey create s3 $AWS_ACCESS_KEY_ID --access-key=\"&lt;access-key&gt;\" --secret-key=\"&lt;secret-access-key&gt;\" --policy=\"policy.json\"\nen remplaçant &lt;access-key&gt; et &lt;secret-access-key&gt; par des noms de votre choix. Idéalement, on donnera un nom simple comme access-key (ex : sa-projet-nomduprojet) mais une clé complexe comme secret-access-key, générable par exemple avec le client gpg :\ngpg --gen-random --armor 1 16\n\nVous pouvez désormais utiliser l’access-key et la secret-access-key pour authentifier les services / applications au bucket spécifié.\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nAttention, les informations d’authentification générées n’apparaissent qu’une seule fois. Elles peuvent ensuite être stockées dans un gestionnaire de mot de passe, un service de stockage de secrets comme Vault, ou bien via la feature d’options de projet d’Onyxia qui permet d’importer le compte de service directement dans les services au moment de leur configuration."
  },
  {
    "objectID": "content/secrets.html",
    "href": "content/secrets.html",
    "title": "Gestion des secrets",
    "section": "",
    "text": "Gestion des secrets\n\nLes variables d’environnement;\nIl arrive que certaines informations doivent être mise à disposition d’un grand nombre d’applications, ou ne doivent pas figurer en clair dans votre code (jetons d’accès, mots de passe, etc.). L’utilisation de variables d’environnement permet de pouvoir accéder à ces informations depuis n’importe quel service.\nAu lancement d’un service, plusieurs variables d’environnement sont déjà injectées automatiquement — par exemple, les tokens d’accès à ``\n\n\n\nCréation et gestion de secrets\nSur la plateforme, les variables d’environnement sont des secrets écrits dans Vault (le coffre fort du Datalab) et sont chiffrées. Cela vous permet d’y stocker des jetons, des identifiants et des mots de passe. La page Mes secrets prends la forme d’un explorateur de fichiers où vous pouvez trier et hiérarchiser vos variables dans des dossiers.\n\nPour commencer :\n\nCréez un nouveau dossier + Nouveau dossier\nPuis dans ce dossier, créez un nouveau secret + Nouveau secret\nOuvrez votre secret\n\n\nChaque secret peut contenir plusieurs variables, composés de paires de clés-valeurs.\n\n+ Ajouter une variable\n\n\n\n\n\n\n\n\nNote\n\n\n\nLes clés (nom de la variable) commencent toujours par$et contiennent uniquement des lettres, des chiffres et le caractère de soulignement (_). Par convention, les clefs s’écrivent en MAJUSCULE.\n\n\nRemplissez le champ du nom de la clef puis sa valeur.\n\n\n\nConvertir des secrets en variables d’environnement\nUne fois votre secret édité, avec ses différentes variables, vous êtes prêt à l’utiliser dans votre service.\n\nCopiez le chemin du secret en cliquant sur le bouton Utiliser dans un service\nPuis au moment de la configuration de votre service, allez dans l’onglet Vaultet collez le chemin du secret dans le champ dédié\n\n\n\nCréez et ouvrez votre service\n\nPour vérifier que vos variables d’environnement ont bien été crées, vous pouvez lancer les commandes suivantes dans le terminal du service :\n# Lister toutes les variables d'environnement disponibles\nenv \n\n# Afficher la valeur d'une variable d'environnement\necho $MA_VARIABLE \n\n# Trouver toutes les variables d'environnement qui contiennent un pattern donné\nenv | grep -i \"&lt;PATTERN&gt;\""
  },
  {
    "objectID": "content/llm/tchat.html",
    "href": "content/llm/tchat.html",
    "title": "Comment utilisez le service ?",
    "section": "",
    "text": "Comment utilisez le service ?\nLa manière la plus simple d’utiliser le service est d’utiliser l’interface de chat proposée par OpenWebUI. Il suffit de se connecter au service via https://llm.lab.sspcloud.fr en utilisant l’authentification SSO de la plateforme, puis de démarrer une nouvelle conversation en sélectionnant le modèle souhaité."
  },
  {
    "objectID": "content/llm/api.html",
    "href": "content/llm/api.html",
    "title": "Utiliser les LLM de façon programmatique",
    "section": "",
    "text": "Pour utiliser les Large Language Models (LLM) de façon programmatique, il est nécessaire de générer une clé d’API. Cette clé vous permettra d’authentifier vos requêtes et d’accéder aux fonctionnalités offertes par le service.\n\nConnexion à la plateforme :\n\nAccédez à la plateforme SSP Cloud via votre navigateur.\nConnectez-vous avec vos identifiants SSO.\n\nGénération de la clé d’API :\n\nUne fois connecté, rendez-vous dans la section dédiée à la gestion des clés d’API.\nCliquez sur votre nom, puis sur “Paramètres” et ensuite sur “Compte”.\nUne section dédiée permet de générer une clé d’API.\n\nSécurisation de la clé :\n\nVous pourrez accéder à votre clé à tout moment.\nNe la partagez pas publiquement pour éviter tout accès non autorisé.\n\n\n\n\n\nL’API proposée par OpenWebUI permet d’interagir avec les LLM de manière programmatique. Voici quelques points clés pour comprendre et utiliser cette API.\n\n\nUne interface OpenAI est disponible : - Endpoint de base : https://llm.lab.sspcloud.fr/api - Authentification : Toutes les requêtes doivent inclure votre clé d’API dans l’en-tête Authorization.\nUn proxy vers l’interface Ollama est également disponible : - Endpoint de base : https://llm.lab.sspcloud.fr/ollama - Authentification : Toutes les requêtes doivent inclure votre clé d’API dans l’en-tête Authorization.\n\n\n\n\n\n\nWarning\n\n\n\nLes clients programmatiques Ollama possèdent rarement la capacité d’ajouter une clé d’API. Ce proxy est donc difficilement utilisable."
  },
  {
    "objectID": "content/llm/api.html#générer-une-clé-dapi",
    "href": "content/llm/api.html#générer-une-clé-dapi",
    "title": "Utiliser les LLM de façon programmatique",
    "section": "",
    "text": "Pour utiliser les Large Language Models (LLM) de façon programmatique, il est nécessaire de générer une clé d’API. Cette clé vous permettra d’authentifier vos requêtes et d’accéder aux fonctionnalités offertes par le service.\n\nConnexion à la plateforme :\n\nAccédez à la plateforme SSP Cloud via votre navigateur.\nConnectez-vous avec vos identifiants SSO.\n\nGénération de la clé d’API :\n\nUne fois connecté, rendez-vous dans la section dédiée à la gestion des clés d’API.\nCliquez sur votre nom, puis sur “Paramètres” et ensuite sur “Compte”.\nUne section dédiée permet de générer une clé d’API.\n\nSécurisation de la clé :\n\nVous pourrez accéder à votre clé à tout moment.\nNe la partagez pas publiquement pour éviter tout accès non autorisé."
  },
  {
    "objectID": "content/llm/api.html#comprendre-lapi-proposée-par-openwebui",
    "href": "content/llm/api.html#comprendre-lapi-proposée-par-openwebui",
    "title": "Utiliser les LLM de façon programmatique",
    "section": "",
    "text": "L’API proposée par OpenWebUI permet d’interagir avec les LLM de manière programmatique. Voici quelques points clés pour comprendre et utiliser cette API.\n\n\nUne interface OpenAI est disponible : - Endpoint de base : https://llm.lab.sspcloud.fr/api - Authentification : Toutes les requêtes doivent inclure votre clé d’API dans l’en-tête Authorization.\nUn proxy vers l’interface Ollama est également disponible : - Endpoint de base : https://llm.lab.sspcloud.fr/ollama - Authentification : Toutes les requêtes doivent inclure votre clé d’API dans l’en-tête Authorization.\n\n\n\n\n\n\nWarning\n\n\n\nLes clients programmatiques Ollama possèdent rarement la capacité d’ajouter une clé d’API. Ce proxy est donc difficilement utilisable."
  },
  {
    "objectID": "content/llm/introduction.html",
    "href": "content/llm/introduction.html",
    "title": "Introduction",
    "section": "",
    "text": "Introduction\nLe SSP Cloud est une plateforme de traitement de données dédiée à l’expérimentation autour des méthodes de data science, en utilisant des données ouvertes. Elle offre un environnement mutualisé pour les utilisateurs, leur permettant de lancer, personnaliser et gérer divers services de manière autonome. Parmi les services disponibles, la mise à disposition de Large Language Models (LLM) à la demande représente une avancée significative. Ces modèles permettent d’automatiser des tâches complexes, d’accélérer l’accès à l’information et d’optimiser les processus métiers. Les LLM facilitent les interactions via le traitement du langage naturel, offrant ainsi des solutions adaptées aux besoins spécifiques des utilisateurs. En intégrant ces technologies, le SSP Cloud se positionne comme un levier essentiel pour améliorer la formation et le maquettage dans le domaine de l’intelligence artificielle.\n\n\nArchitecture\nLe service de mise à disposition des Large Language Models (LLM) à la demande sur le SSP Cloud repose sur une architecture innovante et modulaire. Au cœur de cette architecture se trouve une instance OpenWebUI, qui sert d’interface utilisateur ouverte et flexible. Cette instance OpenWebUI interagit directement avec Ollama, une plateforme avancée de gestion et de déploiement de modèles de langage. Grâce à cette configuration, les utilisateurs peuvent facilement accéder, personnaliser et déployer des modèles LLM selon leurs besoins spécifiques. La liste des modèles disponibles est gérée par les administrateurs de la plateforme et est susceptible d’évoluer au fil du temps pour répondre aux nouvelles exigences et aux avancées technologiques.\n\n\n\n\n\n\nWarning\n\n\n\nSSPCloud ne fournit pas d’accords de niveau de service (SLA) formels ni de garanties concernant la disponibilité du service. Cela signifie que les utilisateurs doivent être prêts à faire face à des interruptions ou des pannes de service potentielles."
  },
  {
    "objectID": "content/principles.html",
    "href": "content/principles.html",
    "title": "Principes du Datalab",
    "section": "",
    "text": "Le projet Onyxia part du constat de difficultés communes rencontrées par les datascientists du secteur public :\n\ndes agents souvent isolés, du fait de la relative rareté des compétences data dans l’administration ;\ndes infrastructures inadaptées, aussi bien en matière de ressources que de technologies, qui constituent un frein à l’innovation ;\nune difficulté à passer de l’expérimentation à la mise en production, du fait de multiples séparations (séparation physique, langage de développement, modes de travail) entre les directions métier et la production informatique.\n\nFace à ce constat, le SSP Cloud a été construit pour proposer une plateforme de mutualisation à plusieurs niveaux :\n\npartage d’une infrastructure moderne, centrée autour du déploiement de services via des conteneurs, et dimensionnée pour les usages de data science ;\npartage de méthodes, via une mutualisation des services de data science proposés, auxquels chacun peut contribuer ;\npartage de connaissances, via des formations associées au Datalab ainsi que la constitution de commaunautés d’entraide centrées sur son utilisation.\n\n\n\n\n\n\n\nNote\n\n\n\nOnyxia, Datalab SSP Cloud : quelles différences ?\nOnyxia est un projet open-source qui propose une plateforme de services de data science, accessible via une application Web. Le SSP Cloud est une instance du projet Onyxia, hébergée à l’Insee.\n\n\n\n\n\nL’architecture du Datalab est basée sur un ensemble de principes fondamentaux :\n\nune production orientée data science, en proposant une infrastructure dimensionnée à la plupart des usages et un catalogue de services couvrant l’ensemble du cycle de vie des projets data ;\ndes choix qui favorisent l’autonomie des usagers, en évitant tout enfermement propriétaire et en permettant l’accès aux couches basses de l’infrastructure pour couvrir les besoins avancés et spécifiques ;\nun projet 100% cloud-natif, mais également cloud-agnostique, permettant un déploiement simple sur n’importe quelle infrastructure ;\nun projet complètement open-source, à la fois du point de vue de ses briques constitutives que de sa diffusion (licence MIT).\n\n\n\n\nLe Datalab est accessible via une interface utilisateur moderne et réactive, centrée sur l’expérience utilisateur. Celle-ci constitue le liant technique entre les différentes composantes d’Onyxia :\n\ndes technologies open-source qui constituent l’état de l’art du déploiement et de l’orchestration de conteneurs, du stockage et de la sécurité ;\nun catalogue de services et d’outils pour accompagner les projets de data science ;\nune plateforme de formation et de documentation pour faciliter l’onboarding sur les technologies proposées.\n\n\n\n\nBriques fondamentales du Datalab Onyxia\n\n\nLe catalogue de services est pensé de manière à accomoder l’essentiel des usages des data scientists, du développement en self-service à la mise en production de traitements ou d’application. L’ensemble du cycle de vie d’un projet data est ainsi couvert, et le catalogue des services est régulièrement étendu pour répondre aux nouveaux besoins des utilisateurs.\n\n\n\nUn catalogue de services complet pour les projets de data science\n\n\n\n\n\nLe projet du Datalab Onyxia est résolument ouvert, à de multiples niveaux :\n\nle Datalab est accessible via son interface Web à tous les agents du service public (via AgentConnect ou une adresse mail en gouv.fr) ainsi qu’aux élèves des écoles de statistique liées à l’Insee (Cefil, Ensai, Ensae) ;\nle code source ouvert et la modularité du projet rendent possible le déploiement d’une instance Onyxia personnalisée sur n’importe quelle infrastructure basée sur un cluster Kubernetes ;\nle projet est ouvert aux contributions extérieures, qu’elles concernent le catalogue des services, l’interface graphique ou l’agencement des briques logicielles qui le constituent."
  },
  {
    "objectID": "content/principles.html#une-plateforme-de-mutualisation",
    "href": "content/principles.html#une-plateforme-de-mutualisation",
    "title": "Principes du Datalab",
    "section": "",
    "text": "Le projet Onyxia part du constat de difficultés communes rencontrées par les datascientists du secteur public :\n\ndes agents souvent isolés, du fait de la relative rareté des compétences data dans l’administration ;\ndes infrastructures inadaptées, aussi bien en matière de ressources que de technologies, qui constituent un frein à l’innovation ;\nune difficulté à passer de l’expérimentation à la mise en production, du fait de multiples séparations (séparation physique, langage de développement, modes de travail) entre les directions métier et la production informatique.\n\nFace à ce constat, le SSP Cloud a été construit pour proposer une plateforme de mutualisation à plusieurs niveaux :\n\npartage d’une infrastructure moderne, centrée autour du déploiement de services via des conteneurs, et dimensionnée pour les usages de data science ;\npartage de méthodes, via une mutualisation des services de data science proposés, auxquels chacun peut contribuer ;\npartage de connaissances, via des formations associées au Datalab ainsi que la constitution de commaunautés d’entraide centrées sur son utilisation.\n\n\n\n\n\n\n\nNote\n\n\n\nOnyxia, Datalab SSP Cloud : quelles différences ?\nOnyxia est un projet open-source qui propose une plateforme de services de data science, accessible via une application Web. Le SSP Cloud est une instance du projet Onyxia, hébergée à l’Insee."
  },
  {
    "objectID": "content/principles.html#principes-fondamentaux",
    "href": "content/principles.html#principes-fondamentaux",
    "title": "Principes du Datalab",
    "section": "",
    "text": "L’architecture du Datalab est basée sur un ensemble de principes fondamentaux :\n\nune production orientée data science, en proposant une infrastructure dimensionnée à la plupart des usages et un catalogue de services couvrant l’ensemble du cycle de vie des projets data ;\ndes choix qui favorisent l’autonomie des usagers, en évitant tout enfermement propriétaire et en permettant l’accès aux couches basses de l’infrastructure pour couvrir les besoins avancés et spécifiques ;\nun projet 100% cloud-natif, mais également cloud-agnostique, permettant un déploiement simple sur n’importe quelle infrastructure ;\nun projet complètement open-source, à la fois du point de vue de ses briques constitutives que de sa diffusion (licence MIT)."
  },
  {
    "objectID": "content/principles.html#offre-de-services",
    "href": "content/principles.html#offre-de-services",
    "title": "Principes du Datalab",
    "section": "",
    "text": "Le Datalab est accessible via une interface utilisateur moderne et réactive, centrée sur l’expérience utilisateur. Celle-ci constitue le liant technique entre les différentes composantes d’Onyxia :\n\ndes technologies open-source qui constituent l’état de l’art du déploiement et de l’orchestration de conteneurs, du stockage et de la sécurité ;\nun catalogue de services et d’outils pour accompagner les projets de data science ;\nune plateforme de formation et de documentation pour faciliter l’onboarding sur les technologies proposées.\n\n\n\n\nBriques fondamentales du Datalab Onyxia\n\n\nLe catalogue de services est pensé de manière à accomoder l’essentiel des usages des data scientists, du développement en self-service à la mise en production de traitements ou d’application. L’ensemble du cycle de vie d’un projet data est ainsi couvert, et le catalogue des services est régulièrement étendu pour répondre aux nouveaux besoins des utilisateurs.\n\n\n\nUn catalogue de services complet pour les projets de data science"
  },
  {
    "objectID": "content/principles.html#un-projet-ouvert",
    "href": "content/principles.html#un-projet-ouvert",
    "title": "Principes du Datalab",
    "section": "",
    "text": "Le projet du Datalab Onyxia est résolument ouvert, à de multiples niveaux :\n\nle Datalab est accessible via son interface Web à tous les agents du service public (via AgentConnect ou une adresse mail en gouv.fr) ainsi qu’aux élèves des écoles de statistique liées à l’Insee (Cefil, Ensai, Ensae) ;\nle code source ouvert et la modularité du projet rendent possible le déploiement d’une instance Onyxia personnalisée sur n’importe quelle infrastructure basée sur un cluster Kubernetes ;\nle projet est ouvert aux contributions extérieures, qu’elles concernent le catalogue des services, l’interface graphique ou l’agencement des briques logicielles qui le constituent."
  },
  {
    "objectID": "content/services-configuration.html",
    "href": "content/services-configuration.html",
    "title": "Configuration des services (en construction)",
    "section": "",
    "text": "Après avoir cliqué sur “Nouveau service” &gt; “RStudio/Jupyter-python/VScode-python” &gt; “Lancer”\n\n\nPour reconnaître le service et/ou la configuration si on l’enregistre en cliquant sur le symbole de marque page en haut à droite. Si le nom existe déjà parmi les configurations enregistrées, l’enregistrement écrasera l’ancienne configuration.\nPratique pour distinguer différents services d’un même type (RStudio, Jupyter…).\n\n\n\nIl est possible de partager un service à un groupe de personnes en cochant la case “Partager le service” à l’ouverture du service. Les autres membres du groupe verront le service et pourront l’utiliser. La création de groupes se fait en écrivant aux administrateurs sur Tchap (en privé) ou par mail à l’adresse innovation@insee.fr, en communiquant le nom de groupe, les noms d’utilisateurs des membres, le besoin ou non d’un espace de stockage associé sur MinIO.\n\nPour un besoin ponctuel, il est aussi possible de partager un service que l’on a créé à une autre personne. Il suffit de lui communiquer l’URL (type https://user-aaaaaaaaaaaaaa-xxxxxxx-x.user.lab.sspcloud.fr/), ainsi que le mot de passe du service. Le nom d’utilisateur reste Onyxia. Attention, il est recommandé de changer le mot de passe du service lors de son lancement (onglet Security) pour ne pas le faire fuiter. Il faudra aussi décocher Enable IP protection et Enable network policy dans l’onglet Security. Une seule personne à la fois peut se connecter à un service RStudio.\n\n\n\n\n\n\n\n\n\n\n\n\nUn lien vers un script shell (enchaînement de commandes linux) qui est exécuté juste après le lancement du service. Pratique pour automatiser la mise en place de certaines configurations.\nCe lien du script doit être accessible sur internet, par exemple sur https://git.lab.sspcloud.fr/ avec un projet public ou sur le stockage S3 avec un fichier public.\nExemple de script d’initialisation qui clone un projet à partir d’une instance Gitlab privée, configure les options globales de RStudio, ouvre automatiquement le projet RStudio cloné, installe et sélectionne la correction orthographique française, personnalise les bribes de codes (snippets).\nVous pouvez également trouver un ensemble de scripts d’initialisation sur notre repo github dédié.\n\n\n\n\n\n\nWarning\n\n\n\nLe script est exécuté en tant que superutilisateur (Root) et les fichiers qu’il crée sont ainsi la propriété du superutilisateur. Ceci génère des erreurs ensuite quand ces fichiers sont appelés, par exemple des fichiers de configuration de RStudio. Pour rendre à l’utilisateur normal (qui s’appelle onyxia) les droit sur son dossier personnel :\nchown -R ${USERNAME}:${GROUPNAME} ${HOME}\n\n\n\n\n\nDes options à passer au script d’initialisation, séparées par des espaces et que l’on peut ensuite appeler avec $1, $2…\nPar exemple si on inscrit dans le champ PersonalInitArgs fichier1.txt fichier2.txt, et qu’on utilise ce script d’initialisation :\n#!/bin/bash\ntouch $1\ntouch $2\nLe script créera via la commande touch deux fichiers fichier1.txt et fichier2.txt.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nC’est le mot de passe à saisir lorsqu’on ouvre un service, celui donné par “Copier le mot de passage” sur la page des services. Il est fourni par le paramètre général “Mot de passe pour vos services” que l’on trouve dans “Mon Compte” &gt; “Informations du compte”, sauf si on en a défini un particulier au niveau du service.\n\n\n\nSi coché, le service n’est accessible que par une seule IP, à décocher si l’on souhaite travailler de deux endroits différents.\n\n\n\n\n\n\n\nPour apprendre à utiliser cet onglet, voir la page dédiée.\n\n\n\n\n\n\nWarning\n\n\n\nIl n’est pas possible de cloner automatiquement un projet privé d’une instance privée (c’est-à-dire autre que gitlab.com et github.com). Pour le faire, il faudra recourir à un script shell comme indiqué ici.\n\n\n\n\nSi coché, configure Git et tente un clone au démarrage du service.\n\n\n\nLe nom qui apparaîtra dans les commits (pas le nom d’utilisateur du compte Gitlab ou Github).\n\n\n\nL’adresse email qui apparaîtra dans les commits (pas forcément le mail associé au compte Gitlab ou Github).\n\n\n\n\n\n\nJeton d’accès défini sur la plateforme utilisée (Gitlab, Github…).\n\n\n\nL’URL obtenue sur la plateforme utilisée (Gitlab, Github…) en cliquant sur “Cloner” &gt; HTTPS.\nDe type :\nhttps://github.com/InseeFrLab/docs.sspcloud.fr.git\n\n\n\n\n\n\n\n\n\n\n\n\nPour apprendre à utiliser cet onglet, voir la page dédiée.\n\n\n\nOptions to pass to the initialization script, separated by spaces and can be subsequently called with $1, $2, etc.\nFor example, if you enter file1.txt file2.txt in the PersonalInitArgs field and use this initialization script:\n#!/bin/bash\ntouch $1\ntouch $2\nThe script will create two files, file1.txt and file2.txt, using the touch command.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis is the password to enter when opening a service, which is provided by “Copy the password” on the service page. It is supplied by the general parameter “Password for your services,” which can be found in “My Account” &gt; “Account Information,” unless a specific one is defined at the service level.\n\n\n\nIf checked, the service is only accessible from a single IP. Uncheck it if you wish to work from different locations.\n\n\n\n\n\n\n\nTo learn how to use this tab, see the dedicated page.\n\n\n\n\n\n\nWarning\n\n\n\nIt is not possible to automatically clone a private project from a private instance (i.e., other than gitlab.com and github.com). To do so, you will need to use a shell script as indicated here.\n\n\n\n\nIf checked, configure Git and attempt a clone when the service starts.\n\n\n\nThe name that will appear in the commits (not the Gitlab or Github account username).\n\n\n\nThe email address that will appear in the commits (not necessarily the email associated with the Gitlab or Github account).\n\n\n\n\n\n\nAccess token defined on the platform used (Gitlab, Github…).\n\n\n\nThe URL obtained from the platform used (Gitlab, Github…) by clicking on “Clone” &gt; HTTPS.\nIn the format:\nhttps://github.com/InseeFrLab/docs.sspcloud.fr.git\n\n\n\n\n\n\n\n\n\n\n\n\nTo learn how to use this tab, see the dedicated page.\n:::"
  },
  {
    "objectID": "content/services-configuration.html#nom-personnalisé",
    "href": "content/services-configuration.html#nom-personnalisé",
    "title": "Configuration des services (en construction)",
    "section": "",
    "text": "Pour reconnaître le service et/ou la configuration si on l’enregistre en cliquant sur le symbole de marque page en haut à droite. Si le nom existe déjà parmi les configurations enregistrées, l’enregistrement écrasera l’ancienne configuration.\nPratique pour distinguer différents services d’un même type (RStudio, Jupyter…)."
  },
  {
    "objectID": "content/services-configuration.html#partager-le-service",
    "href": "content/services-configuration.html#partager-le-service",
    "title": "Configuration des services (en construction)",
    "section": "",
    "text": "Il est possible de partager un service à un groupe de personnes en cochant la case “Partager le service” à l’ouverture du service. Les autres membres du groupe verront le service et pourront l’utiliser. La création de groupes se fait en écrivant aux administrateurs sur Tchap (en privé) ou par mail à l’adresse innovation@insee.fr, en communiquant le nom de groupe, les noms d’utilisateurs des membres, le besoin ou non d’un espace de stockage associé sur MinIO.\n\nPour un besoin ponctuel, il est aussi possible de partager un service que l’on a créé à une autre personne. Il suffit de lui communiquer l’URL (type https://user-aaaaaaaaaaaaaa-xxxxxxx-x.user.lab.sspcloud.fr/), ainsi que le mot de passe du service. Le nom d’utilisateur reste Onyxia. Attention, il est recommandé de changer le mot de passe du service lors de son lancement (onglet Security) pour ne pas le faire fuiter. Il faudra aussi décocher Enable IP protection et Enable network policy dans l’onglet Security. Une seule personne à la fois peut se connecter à un service RStudio."
  },
  {
    "objectID": "content/services-configuration.html#init",
    "href": "content/services-configuration.html#init",
    "title": "Configuration des services (en construction)",
    "section": "",
    "text": "Un lien vers un script shell (enchaînement de commandes linux) qui est exécuté juste après le lancement du service. Pratique pour automatiser la mise en place de certaines configurations.\nCe lien du script doit être accessible sur internet, par exemple sur https://git.lab.sspcloud.fr/ avec un projet public ou sur le stockage S3 avec un fichier public.\nExemple de script d’initialisation qui clone un projet à partir d’une instance Gitlab privée, configure les options globales de RStudio, ouvre automatiquement le projet RStudio cloné, installe et sélectionne la correction orthographique française, personnalise les bribes de codes (snippets).\nVous pouvez également trouver un ensemble de scripts d’initialisation sur notre repo github dédié.\n\n\n\n\n\n\nWarning\n\n\n\nLe script est exécuté en tant que superutilisateur (Root) et les fichiers qu’il crée sont ainsi la propriété du superutilisateur. Ceci génère des erreurs ensuite quand ces fichiers sont appelés, par exemple des fichiers de configuration de RStudio. Pour rendre à l’utilisateur normal (qui s’appelle onyxia) les droit sur son dossier personnel :\nchown -R ${USERNAME}:${GROUPNAME} ${HOME}\n\n\n\n\n\nDes options à passer au script d’initialisation, séparées par des espaces et que l’on peut ensuite appeler avec $1, $2…\nPar exemple si on inscrit dans le champ PersonalInitArgs fichier1.txt fichier2.txt, et qu’on utilise ce script d’initialisation :\n#!/bin/bash\ntouch $1\ntouch $2\nLe script créera via la commande touch deux fichiers fichier1.txt et fichier2.txt."
  },
  {
    "objectID": "content/services-configuration.html#security",
    "href": "content/services-configuration.html#security",
    "title": "Configuration des services (en construction)",
    "section": "",
    "text": "C’est le mot de passe à saisir lorsqu’on ouvre un service, celui donné par “Copier le mot de passage” sur la page des services. Il est fourni par le paramètre général “Mot de passe pour vos services” que l’on trouve dans “Mon Compte” &gt; “Informations du compte”, sauf si on en a défini un particulier au niveau du service.\n\n\n\nSi coché, le service n’est accessible que par une seule IP, à décocher si l’on souhaite travailler de deux endroits différents."
  },
  {
    "objectID": "content/services-configuration.html#git",
    "href": "content/services-configuration.html#git",
    "title": "Configuration des services (en construction)",
    "section": "",
    "text": "Pour apprendre à utiliser cet onglet, voir la page dédiée.\n\n\n\n\n\n\nWarning\n\n\n\nIl n’est pas possible de cloner automatiquement un projet privé d’une instance privée (c’est-à-dire autre que gitlab.com et github.com). Pour le faire, il faudra recourir à un script shell comme indiqué ici.\n\n\n\n\nSi coché, configure Git et tente un clone au démarrage du service.\n\n\n\nLe nom qui apparaîtra dans les commits (pas le nom d’utilisateur du compte Gitlab ou Github).\n\n\n\nL’adresse email qui apparaîtra dans les commits (pas forcément le mail associé au compte Gitlab ou Github).\n\n\n\n\n\n\nJeton d’accès défini sur la plateforme utilisée (Gitlab, Github…).\n\n\n\nL’URL obtenue sur la plateforme utilisée (Gitlab, Github…) en cliquant sur “Cloner” &gt; HTTPS.\nDe type :\nhttps://github.com/InseeFrLab/docs.sspcloud.fr.git\n\n\n\n\n\n\n\n\n\n\n\n\nPour apprendre à utiliser cet onglet, voir la page dédiée.\n\n\n\nOptions to pass to the initialization script, separated by spaces and can be subsequently called with $1, $2, etc.\nFor example, if you enter file1.txt file2.txt in the PersonalInitArgs field and use this initialization script:\n#!/bin/bash\ntouch $1\ntouch $2\nThe script will create two files, file1.txt and file2.txt, using the touch command."
  },
  {
    "objectID": "content/services-configuration.html#security-1",
    "href": "content/services-configuration.html#security-1",
    "title": "Configuration des services (en construction)",
    "section": "",
    "text": "This is the password to enter when opening a service, which is provided by “Copy the password” on the service page. It is supplied by the general parameter “Password for your services,” which can be found in “My Account” &gt; “Account Information,” unless a specific one is defined at the service level.\n\n\n\nIf checked, the service is only accessible from a single IP. Uncheck it if you wish to work from different locations."
  },
  {
    "objectID": "content/services-configuration.html#git-1",
    "href": "content/services-configuration.html#git-1",
    "title": "Configuration des services (en construction)",
    "section": "",
    "text": "To learn how to use this tab, see the dedicated page.\n\n\n\n\n\n\nWarning\n\n\n\nIt is not possible to automatically clone a private project from a private instance (i.e., other than gitlab.com and github.com). To do so, you will need to use a shell script as indicated here.\n\n\n\n\nIf checked, configure Git and attempt a clone when the service starts.\n\n\n\nThe name that will appear in the commits (not the Gitlab or Github account username).\n\n\n\nThe email address that will appear in the commits (not necessarily the email associated with the Gitlab or Github account).\n\n\n\n\n\n\nAccess token defined on the platform used (Gitlab, Github…).\n\n\n\nThe URL obtained from the platform used (Gitlab, Github…) by clicking on “Clone” &gt; HTTPS.\nIn the format:\nhttps://github.com/InseeFrLab/docs.sspcloud.fr.git\n\n\n\n\n\n\n\n\n\n\n\n\nTo learn how to use this tab, see the dedicated page.\n:::"
  },
  {
    "objectID": "content/tutorials/choose-materials.html",
    "href": "content/tutorials/choose-materials.html",
    "title": "Quels supports utiliser pour les formations ?",
    "section": "",
    "text": "Lors de la conception de supports de formation efficaces, il est crucial de choisir des formats qui engagent les apprenants et améliorent leur compréhension. Bien que les PDFs, les présentations et les vidéos soient des moyens utiles de présenter des informations, nous nous concentrerons sur les environnements interactifs, car ils sont idéaux pour la formation pratique. Les environnements interactifs permettent aux apprenants d’appliquer les concepts immédiatement, de tester le code en temps réel et de participer activement à leur apprentissage, ce qui favorise une compréhension approfondie et une meilleure rétention des compétences.\nDans ce qui suit, nous comparerons différents environnements interactifs en fonction du langage utilisé. Une méthode de déploiement d’un site statique sur la plateforme à l’aide de Quarto sera également présentée.\n\n\n🐍 En Python, les notebooks Jupyter, également disponibles dans VSCode, s’imposent comme le choix incontournable. Avec le support des médias riches, des widgets et de nombreuses extensions, ils permettent d’intégrer des graphiques interactifs, des tableaux de données et même des formulaires pour les exercices.\n\n\n\nExemple avec jupyter\n\n\n\n\n\nExemple avec vscode\n\n\n\n\n\n®️ En R, nous pouvons utiliser soit les notebooks R Markdown, soit LearnR, qui propose des tutoriels interactifs intégrés dans des documents R Markdown. Les deux combinent explications, code et visualisation dans un document interactif. Cependant, même si LearnR permet de générer des éléments interactifs et plus complexes tels que des quiz, ce qui le rend idéal pour les tutoriels débutants, il nécessite le déploiement d’un serveur Shiny, ce qui peut être coûteux. De plus, dans LearnR, les cellules ne communiquent pas à l’échelle de tout l’environnement ; ainsi, la définition de variables globales ou la gestion de l’état devient difficile. Cette limitation réduit l’efficacité de LearnR pour des tutoriels complexes où un état connecté et évolutif est nécessaire pour progresser à partir des étapes précédentes.\nDans l’ensemble, bien que LearnR offre un environnement interactif pour R adapté aux exercices simples, les notebooks R Markdown offrent une solution plus robuste, flexible et largement utilisée. Pour R, les sessions interactives locales ou R Markdown traditionnel sont souvent plus pratiques pour des formations complètes.\nC’est pourquoi, pour des supports de formation sophistiqués nécessitant une progression fluide et une gestion de l’état, les notebooks restent le choix privilégié pour les tutoriels en Python ou en R.\n\n\n\nExemple avec rstudio"
  },
  {
    "objectID": "content/tutorials/choose-materials.html#utilisation-de-python",
    "href": "content/tutorials/choose-materials.html#utilisation-de-python",
    "title": "Quels supports utiliser pour les formations ?",
    "section": "",
    "text": "🐍 En Python, les notebooks Jupyter, également disponibles dans VSCode, s’imposent comme le choix incontournable. Avec le support des médias riches, des widgets et de nombreuses extensions, ils permettent d’intégrer des graphiques interactifs, des tableaux de données et même des formulaires pour les exercices.\n\n\n\nExemple avec jupyter\n\n\n\n\n\nExemple avec vscode"
  },
  {
    "objectID": "content/tutorials/choose-materials.html#utilisation-de-r",
    "href": "content/tutorials/choose-materials.html#utilisation-de-r",
    "title": "Quels supports utiliser pour les formations ?",
    "section": "",
    "text": "®️ En R, nous pouvons utiliser soit les notebooks R Markdown, soit LearnR, qui propose des tutoriels interactifs intégrés dans des documents R Markdown. Les deux combinent explications, code et visualisation dans un document interactif. Cependant, même si LearnR permet de générer des éléments interactifs et plus complexes tels que des quiz, ce qui le rend idéal pour les tutoriels débutants, il nécessite le déploiement d’un serveur Shiny, ce qui peut être coûteux. De plus, dans LearnR, les cellules ne communiquent pas à l’échelle de tout l’environnement ; ainsi, la définition de variables globales ou la gestion de l’état devient difficile. Cette limitation réduit l’efficacité de LearnR pour des tutoriels complexes où un état connecté et évolutif est nécessaire pour progresser à partir des étapes précédentes.\nDans l’ensemble, bien que LearnR offre un environnement interactif pour R adapté aux exercices simples, les notebooks R Markdown offrent une solution plus robuste, flexible et largement utilisée. Pour R, les sessions interactives locales ou R Markdown traditionnel sont souvent plus pratiques pour des formations complètes.\nC’est pourquoi, pour des supports de formation sophistiqués nécessitant une progression fluide et une gestion de l’état, les notebooks restent le choix privilégié pour les tutoriels en Python ou en R.\n\n\n\nExemple avec rstudio"
  },
  {
    "objectID": "content/tutorials/introduction.html",
    "href": "content/tutorials/introduction.html",
    "title": "Introduction",
    "section": "",
    "text": "Introduction\nDans le monde de la science des données et de la programmation, disposer d’un environnement de formation flexible et reproductible est essentiel. Pour les enseignants comme pour les étudiants, la possibilité de configurer rapidement des environnements cohérents et prêts à l’emploi est une révolution. Onyxia excelle dans la fourniture de tels environnements. Avec un simple lien, les utilisateurs peuvent lancer des environnements de formation préconfigurés, ce qui en fait un outil idéal pour l’apprentissage pratique. Ce tutoriel explique pourquoi SSP Cloud et les notebooks sont des outils puissants pour la formation, et comment structurer et déployer un cours efficace en utilisant ces technologies.\n\n\nPourquoi utiliser SSP Cloud pour la formation ?\nSSP Cloud permet aux utilisateurs de déployer facilement des espaces de travail dans le cloud, sans les tracas d’une installation locale ou d’une configuration complexe. Voici pourquoi il est particulièrement utile pour la formation :\n\nConfiguration instantanée : Les enseignants peuvent partager un lien qui configure tout – l’environnement, les logiciels et même les jeux de données – afin que les apprenants n’aient rien à installer ou configurer localement.\nCohérence entre les apprenants : En fournissant un environnement reproductible, tout le monde travaille avec la même configuration, minimisant les problèmes de configuration qui surviennent habituellement avec différents systèmes d’exploitation et dépendances.\nÉvolutivité : SSP Cloud peut évoluer en fonction de vos besoins, offrant des ressources informatiques puissantes pour les grands jeux de données ou les tâches intensives en calcul. Cela lui permet de prendre en charge un large éventail de formations, des tutoriels Python pour débutants aux workflows avancés de machine learning.\n\n\n\n\n\n\n\nWarning\n\n\n\nSSPCloud ne fournit pas d’accords de niveau de service (SLA) formels ni de garanties concernant la disponibilité du service. Cela signifie que les utilisateurs doivent être prêts à faire face à des interruptions ou des pannes de service potentielles."
  },
  {
    "objectID": "content/version-control.html",
    "href": "content/version-control.html",
    "title": "Contrôle de version",
    "section": "",
    "text": "Le Datalab est une plateforme mutualisée : les ressources utilisées par les services sont partagées entre les différents utilisateurs. A ce titre, les services du Datalab fonctionnent sur le modèle des conteneurs éphémères : dans un usage standard, l’utilisateur lance un service, réalise des traitements de données, sauvegarde le code qui a permis de réaliser ces traitements, et supprime l’instance du service. Cette sauvegarde du code est grandement facilitée par l’usage du contrôle de version.\nCette considération de performance ne doit cependant pas être vue comme une contrainte : le contrôle de version est une bonne pratique essentielle de développement. Les bénéfices sont nombreux, aussi bien à titre individuel :\n\nle projet local est synchronisé avec un serveur distant, rendant la perte de code quasi impossible ;\nl’historique complet des choix et modifications effectuées sur le projet est conservé ;\nl’utilisateur peut parcourir cet historique pour rechercher les modifications qui ont pu créer des erreurs, et décider à tout moment de revenir à une version précédente du projet, ou bien de certains fichiers.\n\nque dans le cadre de projets collaboratifs :\n\nle travail simultané sur un même projet est possible, sans risque de perte ;\nl’utilisateur peut partager ses modifications tout en bénéficiant de celles des autres ;\nil devient possible de contribuer à des projets open-source, pour lesquels l’usage de Git est très largement standard.\n\n\n\n\n\n\n\nWarning\n\n\n\nCe tutoriel vise à présenter comment le contrôle de version peut être facilement implémenté grâce aux outils présents sur le Datalab. Il ne présente pas le fonctionnement de Git et présuppose donc une certaine familiarité avec l’outil. De nombreuses ressources en ligne peuvent servir d’introduction ; les utilisateurs de R pourront par exemple suivre cette formation et les utilisateurs de Python ce chapitre de cours.\n\n\n\n\n\n\n\nBien qu’une utilisation hors-ligne de Git soit possible, tout l’intérêt du contrôle de version réside dans la synchronisation de la copie locale d’un projet (clone) avec un dépôt distant (remote). Différents services de forge logicielle permettent cette synchronisation des projets Git, dont les plus connus sont GitHubet GitLab. Dans la mesure où le premier dispose aujourd’hui de beaucoup plus de visibilité — par exemple, les dépôts de l’Insee, InseeFret InseeFrLab, sont sur GitHub — le Datalab propose une intégration facilitée avec GitHub, que nous présentons à travers ce tutoriel.\n\n\n\n\n\n\nWarning\n\n\n\nLa suite du tutoriel nécessite de disposer d’un compte GitHub.\n\n\n\n\n\n\n\n\nNote\n\n\n\nSi l’utilisation du Datalab avec la plateforme GitHub est facilitée, elle n’est en aucun cas obligatoire : il reste tout à fait possible d’utiliser la forge logicielle de son choix pour la synchronisation des projets. Une forge basée sur GitLabest notamment mise à disposition des utilisateurs du Datalab.\n\n\n\n\n\nLa synchronisation avec un dépôt distant nécessite une authentification auprès de GitHub. Celle-ci s’effectue à l’aide d’un jeton d’accès personnel, qui doit être généré à partir du compte GitHub de l’utilisateur. Le service de génération est accessible à cette adresse. La documentation GitHub(en Anglais) propose des illustrations pour guider le processus.\nPour générer un jeton, il est nécessaire de choisir un nom de jeton, un délai d’expiration et des droits d’accès (scope). Il est recommandé de choisir un délai court (30 jours) et un accès restreint (repo seulement) afin de limiter les risques de sécurité en cas de diffusion malveillante du jeton.\n\n\n\nConfiguration recommandée pour la génération d’un jeton d’accès GitHub\n\n\nUne fois le jeton généré, ce dernier apparaît à l’écran. Un jeton ne peut être visualisé qu’une seule fois ; en cas de perte, il faudra en générer un nouveau.\n\n\n\nIl est recommandé d’ajouter ses jetons d’accès à un gestionnaire de mots de passe. Le jeton peut également être ajouté à la configuration “Services externes” du compte utilisateur sur le Datalab, ce qui permet au jeton d’être directement accessible au sein des services proposés sur la plateforme.\n\n\n\nAjouter un jeton d’accès GitHub à un compte utilisateur sur le Datalab\n\n\n\n\n\n\n\n\nWarning\n\n\n\nAttention à bien utiliser dans les “Informations du compte” l’adresse mail associée à votre compte GitHub, c’est elle qui permet de lier effectivement les commits que vous effectuerez à votre compte GitHub.\n\n\n\n\n\n\nGit est préconfiguré pour fonctionner nativement avec les différents services pertinents du Datalab. A l’ouverture d’un service, il est possible de configurer certains éléments. Si l’on a ajouté un jeton d’accès GitHub à son compte sur le Datalab, ce dernier est pré-configuré. Il est par ailleurs possible d’indiquer l’URL complète d’un Repository Git (ex : https://github.com/InseeFrLab/onyxia), qui sera alors cloné à l’initialisation dans l’espace de travail de l’instance.\n\n\n\nConfiguration de Git à l’ouverture d’un service\n\n\n\n\nLe jeton d’accès GitHub est disponible dans le terminal des différents services via la variable d’environnement $GIT_PERSONAL_ACCESS_TOKEN. Afin d’éviter de devoir s’authentifier à chaque opération impliquant le dépôt distant (clone, push & pull), il est recommandé de cloner celui-ci en incluant le jeton d’accès dans le lien HTTPS, à l’aide de la commande suivante :\ngit clone https://${GIT_PERSONAL_ACCESS_TOKEN}@github.com/&lt;owner&gt;/&lt;repo&gt;.git\noù &lt;owner&gt; et &lt;repo&gt; sont à remplacer respectivement par le nom d’utilisateur et le nom du dépôt GitHub.\n\n\n\nLes principaux services de production de code disponibles sur le Datalab disposent d’une interface graphique pour faciliter l’utilisation de Git :\n\nRStudio : RStudio propose une interface graphique pour Git native et assez complète. La documentation utilitR présente son fonctionnement en détail ;\nJupyter : le plugin jupyterlab-gitpermet un interfaçage (assez sommaire) de Jupyter avec Git ;\nVSCode : VSCode propose nativement une interface graphique très bien intégrée avec Git et GitHub. Une documentation détaillée(en Anglais) présente les possibilités de l’outil.\n\n\n\n\n\n\n\nWarning\n\n\n\nLes interfaces graphiques facilitent la prise en main de Git, mais ne remplacent jamais complètement l’usage de l’outil via un terminal du fait d’une intégration nécessairement imparfaite. Il est donc utile de se familiariser avec l’usage de Git via le terminal le plus tôt possible."
  },
  {
    "objectID": "content/version-control.html#pourquoi-utiliser-le-contrôle-de-version",
    "href": "content/version-control.html#pourquoi-utiliser-le-contrôle-de-version",
    "title": "Contrôle de version",
    "section": "",
    "text": "Le Datalab est une plateforme mutualisée : les ressources utilisées par les services sont partagées entre les différents utilisateurs. A ce titre, les services du Datalab fonctionnent sur le modèle des conteneurs éphémères : dans un usage standard, l’utilisateur lance un service, réalise des traitements de données, sauvegarde le code qui a permis de réaliser ces traitements, et supprime l’instance du service. Cette sauvegarde du code est grandement facilitée par l’usage du contrôle de version.\nCette considération de performance ne doit cependant pas être vue comme une contrainte : le contrôle de version est une bonne pratique essentielle de développement. Les bénéfices sont nombreux, aussi bien à titre individuel :\n\nle projet local est synchronisé avec un serveur distant, rendant la perte de code quasi impossible ;\nl’historique complet des choix et modifications effectuées sur le projet est conservé ;\nl’utilisateur peut parcourir cet historique pour rechercher les modifications qui ont pu créer des erreurs, et décider à tout moment de revenir à une version précédente du projet, ou bien de certains fichiers.\n\nque dans le cadre de projets collaboratifs :\n\nle travail simultané sur un même projet est possible, sans risque de perte ;\nl’utilisateur peut partager ses modifications tout en bénéficiant de celles des autres ;\nil devient possible de contribuer à des projets open-source, pour lesquels l’usage de Git est très largement standard.\n\n\n\n\n\n\n\nWarning\n\n\n\nCe tutoriel vise à présenter comment le contrôle de version peut être facilement implémenté grâce aux outils présents sur le Datalab. Il ne présente pas le fonctionnement de Git et présuppose donc une certaine familiarité avec l’outil. De nombreuses ressources en ligne peuvent servir d’introduction ; les utilisateurs de R pourront par exemple suivre cette formation et les utilisateurs de Python ce chapitre de cours."
  },
  {
    "objectID": "content/version-control.html#intégration-de-github-avec-le-datalab",
    "href": "content/version-control.html#intégration-de-github-avec-le-datalab",
    "title": "Contrôle de version",
    "section": "",
    "text": "Bien qu’une utilisation hors-ligne de Git soit possible, tout l’intérêt du contrôle de version réside dans la synchronisation de la copie locale d’un projet (clone) avec un dépôt distant (remote). Différents services de forge logicielle permettent cette synchronisation des projets Git, dont les plus connus sont GitHubet GitLab. Dans la mesure où le premier dispose aujourd’hui de beaucoup plus de visibilité — par exemple, les dépôts de l’Insee, InseeFret InseeFrLab, sont sur GitHub — le Datalab propose une intégration facilitée avec GitHub, que nous présentons à travers ce tutoriel.\n\n\n\n\n\n\nWarning\n\n\n\nLa suite du tutoriel nécessite de disposer d’un compte GitHub.\n\n\n\n\n\n\n\n\nNote\n\n\n\nSi l’utilisation du Datalab avec la plateforme GitHub est facilitée, elle n’est en aucun cas obligatoire : il reste tout à fait possible d’utiliser la forge logicielle de son choix pour la synchronisation des projets. Une forge basée sur GitLabest notamment mise à disposition des utilisateurs du Datalab.\n\n\n\n\n\nLa synchronisation avec un dépôt distant nécessite une authentification auprès de GitHub. Celle-ci s’effectue à l’aide d’un jeton d’accès personnel, qui doit être généré à partir du compte GitHub de l’utilisateur. Le service de génération est accessible à cette adresse. La documentation GitHub(en Anglais) propose des illustrations pour guider le processus.\nPour générer un jeton, il est nécessaire de choisir un nom de jeton, un délai d’expiration et des droits d’accès (scope). Il est recommandé de choisir un délai court (30 jours) et un accès restreint (repo seulement) afin de limiter les risques de sécurité en cas de diffusion malveillante du jeton.\n\n\n\nConfiguration recommandée pour la génération d’un jeton d’accès GitHub\n\n\nUne fois le jeton généré, ce dernier apparaît à l’écran. Un jeton ne peut être visualisé qu’une seule fois ; en cas de perte, il faudra en générer un nouveau.\n\n\n\nIl est recommandé d’ajouter ses jetons d’accès à un gestionnaire de mots de passe. Le jeton peut également être ajouté à la configuration “Services externes” du compte utilisateur sur le Datalab, ce qui permet au jeton d’être directement accessible au sein des services proposés sur la plateforme.\n\n\n\nAjouter un jeton d’accès GitHub à un compte utilisateur sur le Datalab\n\n\n\n\n\n\n\n\nWarning\n\n\n\nAttention à bien utiliser dans les “Informations du compte” l’adresse mail associée à votre compte GitHub, c’est elle qui permet de lier effectivement les commits que vous effectuerez à votre compte GitHub."
  },
  {
    "objectID": "content/version-control.html#utiliser-git-avec-les-services-du-datalab",
    "href": "content/version-control.html#utiliser-git-avec-les-services-du-datalab",
    "title": "Contrôle de version",
    "section": "",
    "text": "Git est préconfiguré pour fonctionner nativement avec les différents services pertinents du Datalab. A l’ouverture d’un service, il est possible de configurer certains éléments. Si l’on a ajouté un jeton d’accès GitHub à son compte sur le Datalab, ce dernier est pré-configuré. Il est par ailleurs possible d’indiquer l’URL complète d’un Repository Git (ex : https://github.com/InseeFrLab/onyxia), qui sera alors cloné à l’initialisation dans l’espace de travail de l’instance.\n\n\n\nConfiguration de Git à l’ouverture d’un service\n\n\n\n\nLe jeton d’accès GitHub est disponible dans le terminal des différents services via la variable d’environnement $GIT_PERSONAL_ACCESS_TOKEN. Afin d’éviter de devoir s’authentifier à chaque opération impliquant le dépôt distant (clone, push & pull), il est recommandé de cloner celui-ci en incluant le jeton d’accès dans le lien HTTPS, à l’aide de la commande suivante :\ngit clone https://${GIT_PERSONAL_ACCESS_TOKEN}@github.com/&lt;owner&gt;/&lt;repo&gt;.git\noù &lt;owner&gt; et &lt;repo&gt; sont à remplacer respectivement par le nom d’utilisateur et le nom du dépôt GitHub.\n\n\n\nLes principaux services de production de code disponibles sur le Datalab disposent d’une interface graphique pour faciliter l’utilisation de Git :\n\nRStudio : RStudio propose une interface graphique pour Git native et assez complète. La documentation utilitR présente son fonctionnement en détail ;\nJupyter : le plugin jupyterlab-gitpermet un interfaçage (assez sommaire) de Jupyter avec Git ;\nVSCode : VSCode propose nativement une interface graphique très bien intégrée avec Git et GitHub. Une documentation détaillée(en Anglais) présente les possibilités de l’outil.\n\n\n\n\n\n\n\nWarning\n\n\n\nLes interfaces graphiques facilitent la prise en main de Git, mais ne remplacent jamais complètement l’usage de l’outil via un terminal du fait d’une intégration nécessairement imparfaite. Il est donc utile de se familiariser avec l’usage de Git via le terminal le plus tôt possible."
  }
]